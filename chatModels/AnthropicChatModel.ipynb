{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe5c47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-anthropic\n",
      "  Using cached langchain_anthropic-0.3.21-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting anthropic<1.0.0,>=0.69.0 (from langchain-anthropic)\n",
      "  Using cached anthropic-0.69.0-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.76 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from langchain-anthropic) (0.3.77)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from langchain-anthropic) (2.11.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anthropic<1.0.0,>=0.69.0->langchain-anthropic) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anthropic<1.0.0,>=0.69.0->langchain-anthropic) (1.9.0)\n",
      "Collecting docstring-parser<1,>=0.15 (from anthropic<1.0.0,>=0.69.0->langchain-anthropic)\n",
      "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anthropic<1.0.0,>=0.69.0->langchain-anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anthropic<1.0.0,>=0.69.0->langchain-anthropic) (0.11.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anthropic<1.0.0,>=0.69.0->langchain-anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anthropic<1.0.0,>=0.69.0->langchain-anthropic) (4.14.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\sanjeev\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3.5.0->anthropic<1.0.0,>=0.69.0->langchain-anthropic) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic<1.0.0,>=0.69.0->langchain-anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.69.0->langchain-anthropic) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.69.0->langchain-anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1.0.0,>=0.69.0->langchain-anthropic) (0.16.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-anthropic) (0.4.32)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-anthropic) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-anthropic) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-anthropic) (6.0.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-anthropic) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.76->langchain-anthropic) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-anthropic) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-anthropic) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-anthropic) (2.32.4)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-anthropic) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-anthropic) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-anthropic) (2.5.0)\n",
      "Using cached langchain_anthropic-0.3.21-py3-none-any.whl (32 kB)\n",
      "Using cached anthropic-0.69.0-py3-none-any.whl (337 kB)\n",
      "Using cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: docstring-parser, anthropic, langchain-anthropic\n",
      "\n",
      "   ---------------------------------------- 0/3 [docstring-parser]\n",
      "   ---------------------------------------- 0/3 [docstring-parser]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   ------------- -------------------------- 1/3 [anthropic]\n",
      "   -------------------------- ------------- 2/3 [langchain-anthropic]\n",
      "   ---------------------------------------- 3/3 [langchain-anthropic]\n",
      "\n",
      "Successfully installed anthropic-0.69.0 docstring-parser-0.17.0 langchain-anthropic-0.3.21\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "581cf65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anthropic in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (0.69.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anthropic) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anthropic) (0.17.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anthropic) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anthropic) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anthropic) (4.14.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\sanjeev\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sanjeev\\onedrive\\desktop\\speech emotion recognisation\\.conda\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "808eb0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9a93792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic API Key loaded: True\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Debug check\n",
    "print(\"Anthropic API Key loaded:\", os.getenv(\"ANTHROPIC_API_KEY\") is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f095502",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}, 'request_id': 'req_011CTkcCbtVrMETwntgJGohZ'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# model= ChatAnthropic(model=\"claude-2\", temperature=0)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m=\u001b[39m ChatAnthropic(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclaude-2\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,max_tokens_to_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello! How are you?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32mc:\\Users\\Sanjeev\\OneDrive\\Desktop\\Speech Emotion Recognisation\\.conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    391\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    392\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 395\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    396\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    397\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    398\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    399\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    400\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    401\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    402\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    403\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    404\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    405\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\Sanjeev\\OneDrive\\Desktop\\Speech Emotion Recognisation\\.conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1025\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1023\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1024\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m-> 1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sanjeev\\OneDrive\\Desktop\\Speech Emotion Recognisation\\.conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:842\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    841\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 842\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    843\u001b[0m                 m,\n\u001b[0;32m    844\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    845\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    846\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    847\u001b[0m             )\n\u001b[0;32m    848\u001b[0m         )\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    850\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\Sanjeev\\OneDrive\\Desktop\\Speech Emotion Recognisation\\.conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1091\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1089\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1091\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1092\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1093\u001b[0m     )\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1095\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sanjeev\\OneDrive\\Desktop\\Speech Emotion Recognisation\\.conda\\lib\\site-packages\\langchain_anthropic\\chat_models.py:1762\u001b[0m, in \u001b[0;36mChatAnthropic._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1760\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create(payload)\n\u001b[0;32m   1761\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m anthropic\u001b[38;5;241m.\u001b[39mBadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43m_handle_anthropic_bad_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_output(data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sanjeev\\OneDrive\\Desktop\\Speech Emotion Recognisation\\.conda\\lib\\site-packages\\langchain_anthropic\\chat_models.py:1760\u001b[0m, in \u001b[0;36mChatAnthropic._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1758\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_request_payload(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1760\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m anthropic\u001b[38;5;241m.\u001b[39mBadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1762\u001b[0m     _handle_anthropic_bad_request(e)\n",
      "File \u001b[1;32mc:\\Users\\Sanjeev\\OneDrive\\Desktop\\Speech Emotion Recognisation\\.conda\\lib\\site-packages\\langchain_anthropic\\chat_models.py:1619\u001b[0m, in \u001b[0;36mChatAnthropic._create\u001b[1;34m(self, payload)\u001b[0m\n\u001b[0;32m   1617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m payload:\n\u001b[0;32m   1618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[1;32m-> 1619\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n",
      "File \u001b[1;32mc:\\Users\\Sanjeev\\OneDrive\\Desktop\\Speech Emotion Recognisation\\.conda\\lib\\site-packages\\anthropic\\_utils\\_utils.py:282\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sanjeev\\OneDrive\\Desktop\\Speech Emotion Recognisation\\.conda\\lib\\site-packages\\anthropic\\resources\\messages\\messages.py:930\u001b[0m, in \u001b[0;36mMessages.create\u001b[1;34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[0;32m    924\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    925\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    927\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    928\u001b[0m     )\n\u001b[1;32m--> 930\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/messages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop_sequences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthinking\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sanjeev\\OneDrive\\Desktop\\Speech Emotion Recognisation\\.conda\\lib\\site-packages\\anthropic\\_base_client.py:1324\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1312\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1320\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1321\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1322\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1323\u001b[0m     )\n\u001b[1;32m-> 1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Sanjeev\\OneDrive\\Desktop\\Speech Emotion Recognisation\\.conda\\lib\\site-packages\\anthropic\\_base_client.py:1112\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1109\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1111\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1112\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}, 'request_id': 'req_011CTkcCbtVrMETwntgJGohZ'}"
     ]
    }
   ],
   "source": [
    "# model= ChatAnthropic(model=\"claude-2\", temperature=0)\n",
    "model= ChatAnthropic(model=\"claude-2\", temperature=0,max_tokens_to_sample=10)\n",
    "result = model.invoke(\"Hello! How are you?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1b160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
