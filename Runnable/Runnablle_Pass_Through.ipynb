{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "390b81a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Joke': 'Why did the LangChain agent get a bad review?\\n\\nBecause it was supposed to summarize a novel, but instead it just generated a detailed recipe for making a really complicated sandwich using all the characters as ingredients. Apparently, \"ham-let\" and \"brie-once\" don\\'t pair well.', 'Explanation': 'The joke plays on the following:\\n\\n* **LangChain\\'s Purpose:** LangChain is a framework for developing applications powered by language models (LLMs). A common task for LLMs is summarization.\\n* **Unexpected Output:** The LangChain agent (an application built with LangChain) was supposed to summarize a novel. Instead, it produced something completely nonsensical: a recipe.\\n* **Pun-Based Humor:** The recipe uses the *characters* from the novel as *ingredients*. This is where the puns come in. \"Ham-let\" is a play on \"Hamlet\" (a famous character from Shakespeare), and \"brie-once\" is a play on \"Beyonc√©\" (a famous singer).  The joke implies the agent completely misinterpreted the task and creatively, but inappropriately, used character names.\\n* **Absurdity:** The idea of using characters as sandwich ingredients is inherently absurd and funny. The final line, \"Apparently, \\'ham-let\\' and \\'brie-once\\' don\\'t pair well,\" adds to the humor by treating this ridiculous sandwich combination as if it were a genuine culinary failure.\\n\\nIn short, the joke is funny because it highlights the potential for AI, even sophisticated tools like LangChain, to misinterpret instructions and produce wildly unexpected and humorous results. The pun-based ingredients further amplify the absurdity.'}\n",
      "                        +-------------+                     \n",
      "                        | PromptInput |                     \n",
      "                        +-------------+                     \n",
      "                                *                           \n",
      "                                *                           \n",
      "                                *                           \n",
      "                       +----------------+                   \n",
      "                       | PromptTemplate |                   \n",
      "                       +----------------+                   \n",
      "                                *                           \n",
      "                                *                           \n",
      "                                *                           \n",
      "                   +------------------------+               \n",
      "                   | ChatGoogleGenerativeAI |               \n",
      "                   +------------------------+               \n",
      "                                *                           \n",
      "                                *                           \n",
      "                                *                           \n",
      "                      +-----------------+                   \n",
      "                      | StrOutputParser |                   \n",
      "                      +-----------------+                   \n",
      "                                *                           \n",
      "                                *                           \n",
      "                                *                           \n",
      "              +---------------------------------+           \n",
      "              | Parallel<Joke,Explanation>Input |           \n",
      "              +---------------------------------+           \n",
      "                     ****               ***                 \n",
      "                  ***                      ***              \n",
      "                **                            ***           \n",
      "    +----------------+                           **         \n",
      "    | PromptTemplate |                            *         \n",
      "    +----------------+                            *         \n",
      "             *                                    *         \n",
      "             *                                    *         \n",
      "             *                                    *         \n",
      "+------------------------+                        *         \n",
      "| ChatGoogleGenerativeAI |                        *         \n",
      "+------------------------+                        *         \n",
      "             *                                    *         \n",
      "             *                                    *         \n",
      "             *                                    *         \n",
      "    +-----------------+                    +-------------+  \n",
      "    | StrOutputParser |                    | Passthrough |  \n",
      "    +-----------------+                    +-------------+  \n",
      "                     ****               ***                 \n",
      "                         ***         ***                    \n",
      "                            **     **                       \n",
      "              +----------------------------------+          \n",
      "              | Parallel<Joke,Explanation>Output |          \n",
      "              +----------------------------------+          \n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "from langchain.schema.runnable import RunnableParallel, RunnableSequence,RunnablePassthrough\n",
    "load_dotenv()\n",
    "\n",
    "prompt1=PromptTemplate(\n",
    "    template=\"Generate a joke about {topic}.\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "prompt2=PromptTemplate(\n",
    "    template=\"Explain the joke about {text}.\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "parser=StrOutputParser()\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.5)\n",
    "\n",
    "chain=RunnableSequence(\n",
    "    RunnableSequence(prompt1, model, parser),  # joke is generated here\n",
    "    RunnableParallel({\n",
    "        'Joke': RunnablePassthrough(),  # joke is passed through here\n",
    "        'Explanation': RunnableSequence(prompt2, model, parser)\n",
    "    })\n",
    ")\n",
    "print(chain.invoke({\"topic\":\"LangChain\"}))\n",
    "\n",
    "chain.get_graph().print_ascii()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
